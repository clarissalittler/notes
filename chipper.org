#+STARTUP: latexpreview
* Computer Architecture Notes
** Clock signals
   https://en.wikipedia.org/wiki/Clock_signal
** App C: Pipelining
    I find the wiki entry more readable than the chapter, but we'll go ahead and use both:  https://en.wikipedia.org/wiki/Instruction_pipelining 
https://en.wikipedia.org/wiki/Branch_predictor
   
    What's the basic point of pipelining? Well, ideally it's that instruction execution is split into separate phases such that each clock cycle we can start on a new instruction and move all the others currently "in the pipeline" further down the line. The phases given for the example architecture in the book splits things into five phases for each instruction:
    1. instruction fetching
    2. instruction decode and register fetching
    3. alu instruction execution
    4. loading/writing memory
    5. writing back to result registers

 So in principle you should have an average of 1 instruction finishing per clock cycle, but reality rarely mimics the ideal. The first example given in the text for pipeline fail was if there was only a single communication channel with memory, so after a load instruction is started then when the load actually needs to touch the memory the start of the next instruction, which involves fetching the instruction from memory first, needs to be delayed by a cycle.

Branching is obviously also going to be a problem because if you incorrectly predict the branching then you're going to start processing instructions that you weren't supposed to execute. Now, one of the ways to deal with this is just to proceed as if the branch wasn't taken and, if indeed it wasn't, just continue onwards but if it was then you can cancel the instruction you're currently working on and then in the next cycle load the instruction at the updated PC. You can, apparently, also try reordering things so that you perform instructions that are guaranteed to occur whether or not the branch is taken while you're waiting to compute the branch address. The text calls this delayed branching. As for branch prediction, there's a couple of kinds of branch prediction that the text mentions. The first is what they call "static prediction" which involves ill-described schema for deciding whether a branch should be assumed taken or assumed not-taken. The logic behind this is that most branches are the same every time. Of course, you can't predict all of these things in advance perfectly without running afoul of the halting problem, but I can totally imagine that you can have pretty good heuristics and that's really what all of this is about: heuristics. Dynamic branching involving having a number of bits to keep track of the branching history in order to modify the predictions. If you have just one bit then you're going to predict the last result of the branch (or whatever other branch mapped to it in the tiny collision prone hash table) and if it's wrong then we update the prediction. If you have n-bits then you only change the prediction on the nth mistake. 

Ah, also, there's possible dependency of ALU calculations on further instructions. For example, if you have something like an add that puts a value in a register that's then used in a multiply instruction in the next instruction, you're not going to do the writeback the first add into the register until long after you've retrieved the out of date values for the mult instruction. How do you prevent this? Well, basically you need to have a temporary storage for the results of the various phases so that you can "forward" the values. I'm not entirely sure how this is implemented, but the principle is simple enough. You have some way to keep track of whether or not you're referring to a value that's stored as a temporary result and then getting it from the location. I imagine that this slightly slows down each clock cycle, but it is probably worth it for the pipelining benefit. 
*** Implementing Pipelining
    In the first section, we deal with how the 5-clock cycle phase of an unpipelined simplified MIPS.

    1. Instruction fetch cycle
       1. IR <- Mem[PC]
       2. NPC <- PC + 4; (i.e. temporary program counter incremented by four bytes)
    2. Instruction decode/ register fetch
       1. A <- Regs[rs]
       2. B <- Regs[rt]
       3. Imm <- sign-extended immediate field of IR
    3. different phases depending on the instruction
       - memory reference :: output <- A + Imm (indexing into memory)
       - register only calculations :: output <- op A B
       - register-immediate calculation :: output <- op A Imm
       - branch calculation :: output <- NPC + (Imm << 2); cond <- (A == 0)
    4. memory access/branch completion
       - all phases update the PC first from NPC
       - memory load :: lmd <- mem[output]
       - memory write :: mem[output] <- B
       - branch :: if cond then pc <- output
    5. write output into registers

Now to turn this into a pipelined version we need to add registers between each phase. These registers hold the data from our intermmediary registers in the above version.

**** Addenda
     I don't find a lot of the details about how to connect everything particularly interesting. From skimming, as far as I can tell there's a lot of details about how to forward the information between registers to deal with data dependency in pipelining and details about how and where to deal with the pipelining hazards. For example, the PC is going to be written whenever an IF phase ends and we have the ID cycle compute the branch target and the cond-test. This means adding another arithmetic module just for the ID phase since the normal alu module is busy. Whenver 
**** Difficulty of implementation
     Exceptions are the main thing discussed here. Since synchronous instructions happen within the instruction themselves. When an exception occurs then we need to save the state of the instructions and get back to them later. If there wasn't a branch we just go back to the saved instruction and continue fetching, otherwise we need to evaluate the branch condition and go from there. Delayed branches complicate this because we simultaneously need to know the branch that we're supposed to be evaluating as well as the pointers to the instructions we're supposed to be executing while we compute the branch.

     Skimming this section it sounds like the MIPS example is one of the easier architectures to handle exceptions. In comparison there are some architectures where operations can take more than one clock cycle, which is a definite complication, and architectures where state is changing in the middle of an instruction being execute rather than at the well-defined operation points of MIPS.

     The tl;dr lesson of this section and the previous one is that a certain amount of overhead is needed to make sure that pipelining has as few delays as possible and that the particular of the instruction set design makes a big difference about how easy it is to deal with interrupts.
*** Random Bits on Forwarding
    Alright, so because this was something I figured out while studying but never wrote down I want to do so now:
    there's not just data forwarding because of loads or depending on the result of the alu, but rather there's also data forwarding when it comes to *jumps*. Since you don't want to only calculate when you need the jump after having loaded several other instructions into the pipeline, instead we can make calculating if the jump will be taken as a part of the instruction decoding phase. This means, though, that we need more forwarding to the ID phase to make this reasonable without introducing yet another source of stalls
** Ch 1
*** Estimating reliability
    Well the main thing we covered on the topic is that mean time to failure of any one of an independent set of components can be estimated as the inverse of the sum of their failures-per-unit-time. For a set of redundant components, we estimate the reliability to be 

\[
   \frac{\frac{MTTF_{ind}}{n}}{\frac{MTTR^{n-1}_{ind}}{MTTF^n_{ind}}}
\]

which reduces to 

\[
  \frac{MTTF^n_{ind}}{n MTTR^{n-1}}
\]

or in the case of just two components this is simply 

\[
  \frac{MTTF^{2}}{2 MTTR}
\]

Oh, so because I was silly and messed this up before I want to make a note that if there *is* no time to repair the short hand for estimating the MTTF for a collection of devices involves taking the number of failures per unit time and then dividing the number of failures needed for a collective failure by the failures per unit time. 

I overthought this massively and tried to use the fact the memorylessness to come up with what I thought was a more accurate equation, but I messed it up. This is all based in approximations on [[https://en.wikipedia.org/wiki/Poisson_distribution][Poisson distributions]] which is what I should read a bit more about if I want to feel more comfortable with the approximations. I'm a terrible overthinker when I don't know the full story.
*** Power usage
    Dynamic power of switching a transistor is ~~ capacitive load x V^2, which means that whenever we can reduce the voltage we're going to save on energy proportional to the square in the reduction.
*** Benchmarks
    Basically the point of this section is that most benchmarks are useless because they've been over-engineered so as to be completely not objective measures of performance. They're either rigged, too trivial, or don't generally reflect real usage. The book does, however, like the SPEC set of benchmarks and talks about how performance should be compared with the geometric mean of ratios of the performance of a computer on the program by the reference computer performance, i.e. 

\[
\frac{Execution_{reference}}{Execution_{test}}
\]

as the rations, and as a reminder because this is a concept I use about once a lifetime, here's the wiki page for the [[https://en.wikipedia.org/wiki/Geometric_mean][geometric mean]].
*** Amdahl's Law
\[
  speedup_{overall} = \frac{1}{(1-\text{frac}) + \frac{frac}{speedup_{enhanced}}}
\]
** Ch 3: More on Pipelining
   https://en.wikipedia.org/wiki/Superscalar_processor
*** Instruction Level Parallelism
**** Dependencies
***** Data Dependencies
      The more obviously named kind of dependency, where data being *computed* by one instruction 
      is being used by other instructions, so something like

      #+BEGIN_EXAMPLE
      LOOP: L.D F0 0(R1)
            ADD.D F4,F0,F2
            S.D F4,0(R1)
            DADDUI R1,R1,#-8
            BNE R1,R2,LOOP
      #+END_EXAMPLE
      then instruction 2 has a data dependence on instruction 1
      and instruction 3 has a data dependence on instruction 2
      and similarly instruction 5 is dependent on instruction 4
***** Name Dependencies
      Name dependence means that something like
      #+BEGIN_EXAMPLE
      ADD.D F4,F0,F1
      SUB.D F4,F8,F9
      #+END_EXAMPLE
      which means that you can't swap the order of these since, in the case of an interrupt or something like that we *need* to keep the order right

      the other thing is something like
      #+BEGIN_EXAMPLE
      ADD.D F0,F1,F2
      SUB.D F1,F2,F3
      #+END_EXAMPLE

      which means that you can't swap the order of events without causing the wrong data from the register to be fetched
***** Control Dependence
      this is a little more subtle and is about the ways that instructions being executed depends on the control flow. Basically, we need to be certain that exceptions and data flow are preserved properly. Any time that an instruction is executed when its not supposed to it can mess either of these things up.
***** Dependency chart 
      | Instruction producing result | Instruction using result | Latency |
      | FP ALU                       | FP ALU                   |       3 |
      | FP ALU                       | S.D                      |       2 |
      | L.D                          | FP ALU                   |       1 |
      | L.D                          | S.D                      |       0 |

What does this really mean, though? It means that if you have something like a FP arithmetic operation then this will take a total of 8 cycles instead of 5, with its alu operation taking 4 cycles and being pipeline. That's where this latency comes from. The difference in latency between the fp alu and the s.d is simply that there's an extra cycle before the s.d needs to have the data (right?)
***** Branch prediction
      The most simple form of branch prediction is just keeping a simple set of bits to determine what to do based on prior branches. For example, if you have a single bit then if the bit is a 0 you're going to assume that the branch is not-taken, but if the bit is 1 you're going to assume that the branch is taken. If you're wrong, you flip the bit. That's great, right? The reason why this works so well is that, in general, when you're doing something like a loop you're going to repeat the action you just did almost every time. 

      Now, you can always bump it up to multiple bits and do something like the following scheme: the msb is going to determine our prediction, and if we're wrong we start appropriately flipping the less significant bits until we end up flipping the msb again. So something like
      00 -> branch taken -> 01 -> branch taken -> 11 -> branch not taken -> 1 0 -> branch taken -> 1 1
      something like that. 

      There's also correlated branch prediction, which is pretty cute: you keep around n*2^m bits so you can make a prediction based on the previous m branches using n bits to make the decision based on prior accuracy, so its a 2-fold notion of history.

      UPDATE [2016-01-29 Fri] : there's actually something I should discuss here because I didn't really understand the details at first. Alright, so the local information of the branches are stored in a lookup table indexed by the bottom x bits of the branch's instruction address. In a correlating branch predictor, the last-m branches part is a global indicator and the result of the last-m-branches is concatenated onto the low bits to create a new indexed table, and this is why if you store n-bits for each predictor and you predict based on x-entries and m-previous branches the total data is x * n * 2^m. 

      Tournament selection: alternate between local and global prediction based on past performance. The book barely explains this part, but [[http://www.eng.utah.edu/~cs6810/pres/13-6810-09.pdf][here]] are some slides that mention it in at least a little more detail. It's a lot simpler than they made it sound. The idea is that a *global* correlating branch prediction is about previous m branches period, local correlating branch prediction is about the store history of the branch and its last l-branches. Combining these two would cause a massive explosion in size, but "additively" using them by tying them together with a *third* predictor which says which predictor to pick allows you to get more bang for your buck on predictions
***** Loop Unrolling
      Loop unrolling, in this context, is a way of giving yourself a lot more to play with in terms of having instructions to shuffle around for reordering. That's at least the very rough motivation. So let's take a simple example such as
      #+BEGIN_EXAMPLE
      LOOP : 
      L.D F0, 0(R1)
      ADD.D F4, F0, F2
      S.D F4, 0(R1)
      DADDUI R1,R1, #-8
      BNE R1, R2, LOOP
      #+END_EXAMPLE
then because of necessary stalling this is actually going to be
      #+BEGIN_EXAMPLE
      LOOP : 
      L.D F0, 0(R1)
      -
      ADD.D F4, F0, F2
      -
      -
      S.D F4, 0(R1)
      DADDUI R1,R1, #-8
      -
      BNE R1, R2, LOOP
      #+END_EXAMPLE
      and unrolled two times it's going to look something more like
      #+BEGIN_EXAMPLE
      LOOP:
      L.D F0, 0(R1)
      L.D F1, -8(R1)
      ADD.D F4, F0, F2
      ADD.D F5, F1, F2
      DADDUI R1,R1, #-16
      S.D F4, 16(R1)
      S.D F5, 8(R1)
      BNE R1, R2, LOOP
      #+END_EXAMPLE

Now how about some other examples? Let's say something like 
      #+BEGIN_EXAMPLE
      LOOP:
      L.D F0,0(R1)
      L.D F2,0(R2)
      -
      MULT.D F4,F0,F2
      -
      -
      -
      ADD.D F4,F4,F6
      -
      -
      S.D F4,0(R1)
      DADDUI R1,R1,#-8
      DADDUI R2,R2,#-8
      BNE R1,R3, LOOP
      #+END_EXAMPLE
then our unrolling three times is going to look like
     #+BEGIN_EXAMPLE
      LOOP: 
      L.D F0,0(R1)
      L.3 F2,0(R2)
      -
      MULT.D F4,F0,F2
      -
      -
      -
      ADD.D F4,F4,F6
      -
      -
      S.D F4,0(R1)
      L.D F8,-8(R1)
      L.D F10,-8(R2)
      -
      MULT.D F12,F8,F10
      -
      -
      -
      ADD.D F12,F12,F6
      -
      -
      S.D F12,-8(R1)      
      L.D F14,-16(R1)
      L.D F16,-16(R2)
      -
      MULT.D F18,F14,F16
      -
      -
      -
      ADD.D F18,F18,F6
      -
      -
      S.D F18,-16(R1)
      DADDUI R1,R1,#-24
      DADDUI R2,R2,#-24
      BNE R1,R3, LOOP      
     #+END_EXAMPLE
     Now to schedule this it's going to look like
     #+BEGIN_EXAMPLE
      LOOP: 
      L.D F0,0(R1)
      L.D F2,0(R2)
      L.D F8,-8(R1)
      L.D F10,-8(R2)
      L.D F14,-16(R1)
      L.D F16,-16(R2)
      MULT.D F4,F0,F2
      MULT.D F12,F8,F10
      MULT.D F18,F14,F16
      DADDUI R1,R1,#-24
      DADDUI R2,R2,#-24
      ADD.D F4,F4,F6
      ADD.D F12,F12,F6
      ADD.D F18,F18,F6
      S.D F4,24(R1)
      S.D F12,16(R1)      
      S.D F18,8(R1)
      BNE R1,R3, LOOP      
     #+END_EXAMPLE
***** Scoreboarding
      Alright, so Tomasulo's "algorithm" (which is more of a design scheme than what I'd call an algorithm) 
      https://en.wikipedia.org/wiki/Tomasulo_algorithm
      This is basically the scheme for how to allow controlled out of order executions while maintaining proper data flow and eliminating hazards.

      The execution of an instruction gets broken down to three basic phases
      1. Issue
      2. Execute
      3. Write result

There's a couple of physical pieces here that are very important to the story. The first of them is "reservation stations". The basic idea of a reservation station is that it holds the operation and all the metadata of its operands to actually nab the right data even during an out of order execution. This may not be the perfect way to describe it technically but allowing myself a little allowance I think the rough idea is that

    We have an instruction /I/ that is next in the queue to be dispatched (we also assume that it's a floating point instruction so that the actual operation is long enough to cause issues with out of order processing (what actually happens with loads and stores though that are out of order in the integer pipeline? I mean if you have an operation that uses a load immediately after it then even with forwarding there's a 1-cycle delay. I suppose it doesn't matter much, but it bothers me that this isn't described in the text)). This instruction is going to be put in one of the reservation stations for its operation, but what happens then depends on the state of its operands. If the operands are already in registers then everything is fine and that data is loaded into the reservation station. Otherwise, if the operation depends on operands that are currently running then we put the operation in a place in the reservation station but we put the appropriate link between the reservation table entry for the operation and for its operands (that's the Qj and Qk). When a value is filled in then it's broadcast over the CDB (common data bus) and all the reservation stations that need it "fill in" the value and perform the operation. [fn:1] There are seperate reservations stations/stores/buffers for stores, loads, and possibly different kinds of arithmetic units (like add and mult can be separate). These reservation stations are cleared once we make the broadcast. 

* Footnotes

[fn:1] One detail about this formulation is that we assume that there's enough functional units (or at least that the functional units are pipelined) so that instructions can be issued to the functional units whenever they're ready. 
